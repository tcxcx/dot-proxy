// src/metadata.ts
import { createClient } from "@polkadot-api/substrate-client";
import * as fs from "node:fs/promises";
import {
  metadata,
  v15
} from "@polkadot-api/substrate-bindings";
import { getWsProvider } from "@polkadot-api/ws-provider/node";
import { Worker } from "node:worker_threads";
import { getObservableClient } from "@polkadot-api/observable-client";
import { combineLatest, filter, firstValueFrom } from "rxjs";
import { dirname } from "path";
import { fileURLToPath } from "url";
import * as knownChains from "@polkadot-api/known-chains";
import { withPolkadotSdkCompat } from "@polkadot-api/polkadot-sdk-compat";
import { startFromWorker } from "@polkadot-api/smoldot/from-node-worker";
import { getSmProvider } from "@polkadot-api/sm-provider";
var workerPath = fileURLToPath(
  import.meta.resolve("@polkadot-api/smoldot/node-worker")
);
var smoldotWorker;
var workerRefCount = 0;
async function getSmoldotWorker() {
  if (!smoldotWorker) {
    const worker = new Worker(workerPath, {
      stdout: true,
      stderr: true
    });
    const client = startFromWorker(worker);
    smoldotWorker = [client, worker];
  }
  return smoldotWorker;
}
var getMetadataCall = async (provider) => {
  const client = getObservableClient(createClient(provider));
  const { runtime$, unfollow, genesis$ } = client.chainHead$();
  const { runtime, genesis } = await firstValueFrom(
    combineLatest({
      runtime: runtime$.pipe(filter(Boolean)),
      genesis: genesis$
    })
  );
  unfollow();
  client.destroy();
  return {
    metadata: runtime.lookup.metadata,
    metadataRaw: runtime.metadataRaw,
    genesis
  };
};
var getChainSpecs = (chain) => {
  if (!(chain in knownChains)) {
    const relayChainName2 = JSON.parse(chain).relay_chain;
    return {
      potentialRelayChainSpecs: relayChainName2 in knownChains ? [knownChains[relayChainName2]] : [],
      chainSpec: chain
    };
  }
  const relayChainName = Object.keys(knownChains).find(
    (c) => c !== chain && chain.startsWith(c)
  );
  const potentialRelayChainSpecs = relayChainName ? [knownChains[relayChainName]] : [];
  const chainSpec = knownChains[chain];
  return {
    potentialRelayChainSpecs,
    chainSpec
  };
};
var getMetadataFromSmoldot = async (chain) => {
  workerRefCount++;
  try {
    const [smoldot] = await getSmoldotWorker();
    const chainSpecs = getChainSpecs(chain);
    const potentialRelayChains = await Promise.all(
      chainSpecs.potentialRelayChainSpecs.map(
        (chainSpec) => smoldot.addChain({ chainSpec })
      )
    );
    const provider = getSmProvider(
      smoldot.addChain({
        chainSpec: chainSpecs.chainSpec,
        potentialRelayChains
      })
    );
    return await getMetadataCall(provider);
  } finally {
    workerRefCount--;
    if (workerRefCount === 0) {
      const [smoldot, worker] = smoldotWorker;
      smoldotWorker = null;
      await smoldot.terminate();
      await worker.terminate();
    }
  }
};
var getMetadataFromWsURL = async (wsURL) => getMetadataCall(withPolkadotSdkCompat(getWsProvider(wsURL)));
async function getMetadata(entry) {
  if (entry.metadata) {
    const data = await fs.readFile(entry.metadata);
    const metadataRaw = new Uint8Array(data);
    let meta;
    try {
      meta = metadata.dec(metadataRaw).metadata.value;
    } catch (_) {
      meta = v15.dec(metadataRaw);
    }
    return {
      metadata: meta,
      metadataRaw,
      genesis: entry.genesis
    };
  }
  if ("chain" in entry) {
    return getMetadataFromSmoldot(entry.chain);
  }
  if ("chainSpec" in entry) {
    const chainSpec = await fs.readFile(entry.chainSpec, "utf8");
    return getMetadataFromSmoldot(chainSpec);
  }
  if ("wsUrl" in entry) {
    return getMetadataFromWsURL(entry.wsUrl);
  }
  return null;
}
async function writeMetadataToDisk(metadataRaw, outFile) {
  await fs.mkdir(dirname(outFile), { recursive: true });
  await fs.writeFile(outFile, metadataRaw);
}

// src/papiConfig.ts
import fsExists from "fs.promises.exists";
import { readPackage } from "read-pkg";
import { mkdir as mkdir2, readFile as readFile2, writeFile as writeFile2 } from "node:fs/promises";
import { join } from "node:path";
import { existsSync } from "node:fs";
var papiFolder = ".papi";
var papiCfgDefaultFile = "polkadot-api.json";
var packageJsonKey = "polkadot-api";
var defaultConfig = {
  version: 0,
  descriptorPath: join(papiFolder, "descriptors"),
  entries: {}
};
async function readPapiConfig(configFile) {
  if (configFile) return readFromFile(configFile);
  const currentVersionLocation = join(papiFolder, papiCfgDefaultFile);
  const currentVersionLocationExists = await fsExists(currentVersionLocation);
  const readConfig = await (currentVersionLocationExists ? readFromFile(currentVersionLocation) : readFromFile(papiCfgDefaultFile)) ?? await readFromPackageJson();
  if (readConfig && !currentVersionLocationExists) {
    await writePapiConfig(void 0, readConfig);
  }
  return readConfig;
}
async function writePapiConfig(configFile, config) {
  if (configFile) return writeToFile(configFile, config);
  if (!existsSync(papiFolder)) {
    await mkdir2(papiFolder);
  }
  return writeToFile(join(papiFolder, papiCfgDefaultFile), config);
}
async function readFromFile(file) {
  const fileExists = await fsExists(file);
  if (!fileExists) return null;
  return migrate(JSON.parse(await readFile2(file, "utf8")));
}
async function readFromPackageJson() {
  const packageJson = await readPackage();
  if (!(packageJsonKey in packageJson)) return null;
  console.warn("Papi config in package.json is deprecated");
  return migrate(packageJson[packageJsonKey]);
}
function migrate(content) {
  if (typeof content.version === "number") {
    return content;
  }
  return {
    ...defaultConfig,
    entries: content
  };
}
async function writeToFile(file, config) {
  if (file === "package.json") {
    throw new Error("Papi config in package.json is deprecated");
  }
  return writeFile2(file, JSON.stringify(config, null, 2));
}

// src/commands/generate.ts
import {
  generateInkTypes,
  generateMultipleDescriptors
} from "@polkadot-api/codegen";
import { getInkLookup } from "@polkadot-api/ink-contracts";
import {
  EntryPointCodec,
  TypedefCodec
} from "@polkadot-api/metadata-compatibility";
import {
  Binary,
  h64,
  Tuple,
  Vector
} from "@polkadot-api/substrate-bindings";
import { spawn } from "child_process";
import { existsSync as existsSync2 } from "fs";
import fsExists2 from "fs.promises.exists";
import fs2, { mkdtemp, rm } from "fs/promises";
import { tmpdir } from "os";
import path, { join as join3, posix, win32 } from "path";
import process2 from "process";
import { readPackage as readPackage2 } from "read-pkg";
import tsc from "tsc-prog";
import tsup, { build } from "tsup";
import { updatePackage } from "write-package";

// src/packageManager.ts
import { readdir } from "node:fs/promises";
import { join as join2 } from "node:path";
import { execa } from "execa";
var detected = null;
async function detectPackageManager() {
  if (detected) return detected;
  const { packageManager, executable } = await detectByLockFile() ?? detectByEnvironment() ?? getFallback();
  const version = await getVersion(executable);
  return detected = {
    packageManager,
    executable,
    version
  };
}
async function detectByLockFile() {
  try {
    for (let i = 0, dir = "."; i < 5; i++, dir = join2(dir, "..")) {
      const packageManager = await getByLockFile(dir);
      if (packageManager) {
        return {
          packageManager,
          executable: packageManager
        };
      }
    }
  } catch (ex) {
  }
  return null;
}
var lockFileToPackageManager = {
  "pnpm-lock.yaml": "pnpm",
  "yarn.lock": "yarn",
  "bun.lockb": "bun",
  "package-lock.json": "npm"
};
var lockFiles = new Set(Object.keys(lockFileToPackageManager));
async function getByLockFile(dir) {
  const files = await readdir(dir);
  const lockFile = files.find((v) => lockFiles.has(v));
  return lockFile ? lockFileToPackageManager[lockFile] : null;
}
function detectByEnvironment() {
  const npm_execpath = process.env.npm_execpath;
  if (npm_execpath) {
    const packageManager = Object.values(lockFileToPackageManager).find(
      (manager) => npm_execpath.includes(manager)
    );
    return packageManager ? { packageManager, executable: npm_execpath } : null;
  }
  if (process.env.PNPM_PACKAGE_NAME) {
    return { packageManager: "pnpm", executable: "pnpm" };
  }
  return null;
}
function getFallback() {
  console.warn("Package manager couldn't be detected, fallback to npm");
  return {
    executable: "npm",
    packageManager: "npm"
  };
}
async function getVersion(executable) {
  const res = await execa(executable, ["--version"]);
  return res.stdout;
}

// src/commands/generate.ts
async function generate(opts) {
  if (process2.env.PAPI_SKIP_GENERATE) {
    return;
  }
  const config = await readPapiConfig(opts.config);
  if (!config) {
    throw new Error("Can't find the Polkadot-API configuration");
  }
  const sources = config.entries;
  if (Object.keys(sources).length == 0) {
    console.log("No chains defined in config file");
  }
  console.log(`Reading metadata`);
  const chains = await Promise.all(
    Object.entries(sources).map(async ([key, source]) => ({
      key,
      ...await getMetadata(source),
      knownTypes: {}
    }))
  );
  console.log(`Generating descriptors`);
  await cleanDescriptorsPackage(config.descriptorPath);
  if (!config.options?.noDescriptorsPackage) {
    await addDescriptorsToPackageJson(config.descriptorPath);
  }
  const descriptorsDir = join3(process2.cwd(), config.descriptorPath);
  const clientPath = opts.clientLibrary ?? "polkadot-api";
  const whitelist = opts.whitelist ? await readWhitelist(opts.whitelist) : null;
  const descriptorSrcDir = join3(descriptorsDir, "src");
  const hash = await outputCodegen(
    chains,
    descriptorSrcDir,
    clientPath,
    whitelist
  );
  if (config.ink) {
    outputInkCodegen(config.ink, descriptorSrcDir);
  }
  await replacePackageJson(descriptorsDir, hash);
  await compileCodegen(descriptorsDir);
  await fs2.rm(descriptorSrcDir, { recursive: true });
  if (!config.options?.noDescriptorsPackage) {
    await runInstall();
    await flushBundlerCache();
  }
}
async function cleanDescriptorsPackage(path2) {
  const descriptorsDir = join3(process2.cwd(), path2);
  if (!existsSync2(descriptorsDir)) {
    await fs2.mkdir(descriptorsDir, { recursive: true });
    await fs2.writeFile(
      join3(descriptorsDir, ".gitignore"),
      "*\n!.gitignore\n!package.json"
    );
  }
  const distDir = join3(descriptorsDir, "dist");
  if (existsSync2(distDir)) {
    await fs2.rm(distDir, { recursive: true });
  }
}
async function addDescriptorsToPackageJson(path2) {
  const [packageJson, protocol] = await Promise.all([
    readPackage2(),
    getPackageProtocol()
  ]);
  const packageSource = `${protocol}:${path2}`;
  const currentSource = packageJson.dependencies?.["@polkadot-api/descriptors"];
  if (currentSource !== packageSource) {
    await updatePackage({
      dependencies: {
        "@polkadot-api/descriptors": packageSource
      }
    });
  }
}
async function getPackageProtocol() {
  const { packageManager, version } = await detectPackageManager();
  switch (packageManager) {
    case "yarn":
      const yarnMajorVersion = Number(version.split(".").at(0));
      return yarnMajorVersion >= 2 ? "portal" : "file";
    default:
      return "file";
  }
}
async function runInstall() {
  const { executable } = await detectPackageManager();
  console.log(`${executable} install`);
  const child = spawn(executable, ["install"], {
    stdio: "inherit",
    shell: true,
    env: {
      ...process2.env,
      PAPI_SKIP_GENERATE: "true"
    }
  });
  await new Promise((resolve) => child.on("close", resolve));
}
var generateMetadataExportFile = (input) => `const binMeta: string = "${Buffer.from(input).toString("base64")}"; export default binMeta;`;
async function outputCodegen(chains, outputFolder, clientPath, whitelist) {
  const {
    descriptorsFileContent,
    descriptorTypesFiles,
    metadataTypes,
    typesFileContent,
    publicTypes
  } = generateMultipleDescriptors(
    chains,
    {
      client: clientPath,
      metadataTypes: "./metadataTypes",
      types: "./common-types",
      descriptorValues: "./descriptors"
    },
    {
      whitelist: whitelist ?? void 0
    }
  );
  const hash = h64(
    Binary.fromText(
      Array.from(metadataTypes.checksumToIdx.keys()).join("")
    ).asBytes()
  );
  const EntryPointsCodec = Vector(EntryPointCodec);
  const TypedefsCodec = Vector(TypedefCodec);
  const TypesCodec = Tuple(EntryPointsCodec, TypedefsCodec);
  await fs2.mkdir(outputFolder, { recursive: true });
  const metadataTypesBase64 = Buffer.from(
    TypesCodec.enc([metadataTypes.entryPoints, metadataTypes.typedefs])
  ).toString("base64");
  await fs2.writeFile(
    path.join(outputFolder, "metadataTypes.ts"),
    `
const content = "${metadataTypesBase64}"
export default content
    `
  );
  await fs2.writeFile(
    path.join(outputFolder, "descriptors.ts"),
    descriptorsFileContent
  );
  await fs2.writeFile(
    path.join(outputFolder, "common-types.ts"),
    typesFileContent
  );
  await Promise.all(
    chains.map((chain, i) => [
      fs2.writeFile(
        join3(outputFolder, `${chain.key}.ts`),
        descriptorTypesFiles[i].content
      ),
      fs2.writeFile(
        join3(outputFolder, `${chain.key}_metadata.ts`),
        generateMetadataExportFile(chain.metadataRaw)
      )
    ]).flat()
  );
  await generateIndex(
    outputFolder,
    chains.map((chain) => chain.key),
    descriptorTypesFiles.map((d) => d.exports),
    publicTypes
  );
  return hash;
}
async function outputInkCodegen(contracts, outputFolder) {
  console.log("Generating ink! types");
  const contractsFolder = join3(outputFolder, "contracts");
  if (!existsSync2(contractsFolder))
    await fs2.mkdir(contractsFolder, { recursive: true });
  const imports = [];
  for (const [key, metadata2] of Object.entries(contracts)) {
    try {
      const types = generateInkTypes(
        getInkLookup(JSON.parse(await fs2.readFile(metadata2, "utf-8")))
      );
      await fs2.writeFile(join3(contractsFolder, `${key}.ts`), types);
      imports.push(`export { descriptor as ${key} } from './${key}'`);
    } catch (ex) {
      console.error("Exception when generating descriptors for contract " + key);
      console.error(ex);
    }
  }
  await fs2.writeFile(
    join3(contractsFolder, `index.ts`),
    imports.join("\n") + "\n"
  );
  fs2.appendFile(
    join3(outputFolder, "index.ts"),
    `
    export * as contracts from './contracts';
    `
  );
}
async function compileCodegen(packageDir) {
  const srcDir = join3(packageDir, "src");
  const outDir = join3(packageDir, "dist");
  if (await fsExists2(outDir)) {
    await fs2.rm(outDir, { recursive: true });
  }
  await tsup.build({
    format: ["cjs", "esm"],
    entry: [path.join(srcDir, "index.ts").replaceAll(win32.sep, posix.sep)],
    loader: {
      ".scale": "binary"
    },
    platform: "neutral",
    outDir,
    outExtension: (ctx) => ({
      js: ctx.format === "esm" ? ".mjs" : ".js"
    })
  });
  tsc.build({
    basePath: srcDir,
    compilerOptions: {
      skipLibCheck: true,
      declaration: true,
      emitDeclarationOnly: true,
      target: "esnext",
      module: "esnext",
      moduleResolution: "node",
      resolveJsonModule: true,
      allowSyntheticDefaultImports: true,
      outDir
    }
  });
}
var generateIndex = async (path2, keys, exports, publicTypes) => {
  const indexTs = [
    ...keys.flatMap((key, i) => [
      `export { ${exports[i].join(",")} } from "./${key}";`,
      `export type * from "./${key}";`
    ]),
    `export {`,
    publicTypes.join(", "),
    `} from './common-types';`
  ].join("\n");
  await fs2.writeFile(join3(path2, "index.ts"), indexTs);
};
async function replacePackageJson(descriptorsDir, version) {
  await fs2.writeFile(
    join3(descriptorsDir, "package.json"),
    `{
  "version": "0.1.0-autogenerated.${version}",
  "name": "@polkadot-api/descriptors",
  "files": [
    "dist"
  ],
  "exports": {
    ".": {
      "types": "./dist/index.d.ts",
      "module": "./dist/index.mjs",
      "import": "./dist/index.mjs",
      "require": "./dist/index.js"
    },
    "./package.json": "./package.json"
  },
  "main": "./dist/index.js",
  "module": "./dist/index.mjs",
  "browser": "./dist/index.mjs",
  "types": "./dist/index.d.ts",
  "sideEffects": false,
  "peerDependencies": {
    "polkadot-api": "*"
  }
}
`
  );
}
async function readWhitelist(filename) {
  if (!await fsExists2(filename)) {
    throw new Error("Whitelist file not found: " + filename);
  }
  const tmpDir = await mkdtemp(join3(tmpdir(), "papi-"));
  try {
    await build({
      format: "esm",
      entry: {
        index: filename
      },
      outDir: tmpDir,
      outExtension() {
        return { js: ".mjs" };
      },
      silent: true
    });
    const { whitelist } = await import(join3(tmpDir, "index.mjs"));
    return whitelist;
  } finally {
    await rm(tmpDir, { recursive: true }).catch(console.error);
  }
}
async function flushBundlerCache() {
  try {
    const viteMetadata = join3(
      process2.cwd(),
      "node_modules",
      ".vite",
      "deps",
      "_metadata.json"
    );
    if (await fsExists2(viteMetadata)) {
      await rm(viteMetadata);
    }
  } catch (ex) {
    console.error(ex);
  }
}

// src/commands/add.ts
import { compactNumber } from "@polkadot-api/substrate-bindings";
import { fromHex } from "@polkadot-api/utils";
import { getMetadataFromRuntime } from "@polkadot-api/wasm-executor";
import * as fs3 from "node:fs/promises";
import ora from "ora";
import { join as join4 } from "node:path";
import { existsSync as existsSync3 } from "node:fs";
async function add(key, options) {
  const config = await readPapiConfig(options.config) ?? defaultConfig;
  const entries = config.entries;
  if (key in entries) {
    console.warn(`Replacing existing ${key} config`);
  }
  if (options.file) {
    entries[key] = {
      metadata: options.file
    };
  } else if (options.wasm) {
    const spinner = ora(`Loading metadata from runtime`).start();
    const metadataHex = (await fs3.readFile(options.wasm)).toString("hex");
    const opaqueMeta = fromHex(getMetadataFromRuntime(`0x${metadataHex}`));
    const metadataLen = compactNumber.dec(opaqueMeta);
    const compactLen = compactNumber.enc(metadataLen).length;
    if (opaqueMeta.length - compactLen !== metadataLen)
      throw new Error("Not able to retrieve runtime metadata");
    spinner.text = "Writing metadata";
    const metadataRaw = opaqueMeta.slice(compactLen);
    const filename = await storeMetadata(metadataRaw, key);
    entries[key] = {
      metadata: filename
    };
  } else {
    const entry = entryFromOptions(options);
    entries[key] = entry;
    if (!options.noPersist) {
      const spinner = ora(`Loading metadata`).start();
      const { metadataRaw, genesis } = await getMetadata(entry);
      spinner.text = "Writing metadata";
      const filename = await storeMetadata(metadataRaw, key);
      spinner.succeed(`Metadata saved as ${filename}`);
      entry.metadata = filename;
      entry.genesis = genesis;
    }
  }
  await writePapiConfig(options.config, config);
  console.log(`Saved new spec "${key}"`);
  if (!options.skipCodegen) {
    generate({
      config: options.config
    });
  }
}
async function storeMetadata(metadata2, key) {
  const defaultFolder = join4(papiFolder, "metadata");
  if (!existsSync3(defaultFolder)) {
    await fs3.mkdir(defaultFolder, { recursive: true });
  }
  const filename = join4(defaultFolder, `${key}.scale`);
  await writeMetadataToDisk(metadata2, filename);
  return filename;
}
var entryFromOptions = (options) => {
  if (options.wsUrl) {
    return {
      wsUrl: options.wsUrl
    };
  }
  if (options.chainSpec) {
    return {
      chainSpec: options.chainSpec
    };
  }
  if (options.name) {
    return {
      chain: options.name
    };
  }
  throw new Error(
    "add command needs one source, specified by options -f -w -c or -n"
  );
};

// src/commands/ink.ts
import { existsSync as existsSync4 } from "node:fs";
import * as fs4 from "node:fs/promises";
import { join as join5 } from "node:path";
var ink = {
  async add(file, options) {
    const metadata2 = JSON.parse(await fs4.readFile(file, "utf-8"));
    delete metadata2.source?.wasm;
    const key = options.key || metadata2.contract.name;
    const config = await readPapiConfig(options.config) ?? defaultConfig;
    const inkConfig = config.ink ||= {};
    if (key in inkConfig) {
      console.warn(`Replacing existing ${key} config`);
    }
    const contractsFolder = join5(papiFolder, "contracts");
    if (!existsSync4(contractsFolder)) {
      await fs4.mkdir(contractsFolder, { recursive: true });
    }
    const fileName = join5(contractsFolder, key + ".json");
    await fs4.writeFile(fileName, JSON.stringify(metadata2, null, 2));
    inkConfig[key] = fileName;
    await writePapiConfig(options.config, config);
    if (!options.skipCodegen) {
      generate({
        config: options.config
      });
    }
  },
  async remove(key, options) {
    const config = await readPapiConfig(options.config) ?? defaultConfig;
    const inkConfig = config.ink ||= {};
    if (!(key in inkConfig)) {
      console.log(`${key} contract not found in config`);
      return;
    }
    const fileName = inkConfig[key];
    delete inkConfig[key];
    if (existsSync4(fileName)) {
      await fs4.rm(fileName);
    }
    await writePapiConfig(options.config, config);
    if (!options.skipCodegen) {
      generate({
        config: options.config
      });
    }
  }
};

// src/commands/remove.ts
async function remove(key, options) {
  const config = await readPapiConfig(options.config) ?? defaultConfig;
  const entries = config.entries;
  if (!(key in entries)) {
    throw new Error(`Key ${key} not set in polkadot-api config`);
  }
  delete entries[key];
  await writePapiConfig(options.config, config);
  console.log(`Removed chain "${key}" from config`);
  if (!options.skipCodegen) {
    generate({
      config: options.config
    });
  }
}

// src/commands/update.ts
import ora2 from "ora";
async function update(keysInput, options) {
  const config = await readPapiConfig(options.config) ?? defaultConfig;
  const { entries } = config;
  const keys = keysInput === void 0 ? Object.keys(entries) : keysInput.split(",");
  const updateByKey = async (key) => {
    if (!(key in entries)) {
      throw new Error(`Key ${key} not set in polkadot-api config`);
    }
    const { metadata: filename, ...entry } = entries[key];
    if (!filename) {
      if (keysInput !== void 0) {
        console.warn(`Key ${key} doesn't have a metadata file to update`);
      }
      return;
    }
    const metadata2 = await getMetadata(entry);
    if (!metadata2) {
      if (keysInput !== void 0) {
        console.warn(
          `Key ${key} doesn't have any external source to update from`
        );
      }
      return;
    }
    entries[key].genesis = metadata2.genesis;
    spinner.text = `Writing ${key} metadata`;
    await writeMetadataToDisk(metadata2.metadataRaw, filename);
    spinner.succeed(`${key} metadata updated`);
  };
  const spinner = ora2(`Updating`).start();
  await Promise.all(keys.map(updateByKey));
  await writePapiConfig(options.config, config);
  if (!options.skipCodegen) {
    console.log(`Updating descriptors`);
    await generate({
      config: options.config
    });
  }
  spinner.stop();
  console.log(`Updated chain(s) "${keys.join(", ")}"`);
}

// src/cli.ts
import { Option, program } from "@commander-js/extra-typings";
import * as knownChains2 from "@polkadot-api/known-chains";
function getCli({
  add: add2,
  generate: generate2,
  remove: remove2,
  update: update2,
  ink: ink2,
  version
}) {
  program.name("polkadot-api").description("Polkadot API CLI").version(version);
  const config = new Option("--config <filename>", "Source for the config file");
  const skipCodegen = new Option(
    "--skip-codegen",
    "Skip running codegen after adding"
  );
  const whitelist = new Option(
    "--whitelist <filename>",
    "Use whitelist file to reduce descriptor size"
  );
  program.command("generate", {
    isDefault: true
  }).description("Generate descriptor files").addOption(config).addOption(whitelist).action(generate2);
  program.command("add").description("Add a new chain spec to the list").argument("<key>", "Key identifier for the chain spec").addOption(config).option("-f, --file <filename>", "Source from metadata encoded file").option("-w, --wsUrl <URL>", "Source from websocket url").option("-c, --chainSpec <filename>", "Source from chain spec file").addOption(
    new Option("-n, --name <name>", "Source from a well-known chain").choices(
      Object.keys(knownChains2)
    )
  ).option("--wasm <filename>", "Source from runtime wasm file").option("--no-persist", "Do not persist the metadata as a file").addOption(skipCodegen).addOption(whitelist).action(add2);
  program.command("update").description("Update the metadata files and generate descriptor files").argument(
    "[keys]",
    "Keys of the metadata files to update, separated by commas. Leave empty for all"
  ).addOption(config).addOption(skipCodegen).addOption(whitelist).action(update2);
  program.command("remove").description("Remove a chain spec from the list").argument("<key>", "Key identifier for the chain spec").addOption(config).addOption(skipCodegen).addOption(whitelist).action(remove2);
  const inkCommand = program.command("ink").description("Add, update or remove ink contracts");
  inkCommand.command("add").description("Add or update an ink contract").argument("<file>", ".contract or .json metadata file for the contract").option("-k, --key <key>", "Key identifier for the contract").addOption(config).addOption(skipCodegen).addOption(whitelist).action(ink2.add);
  inkCommand.command("remove").description("Remove an ink contract").argument("<key>", "Key identifier for the contract to remove").addOption(config).addOption(skipCodegen).addOption(whitelist).action(ink2.remove);
  return program;
}

export {
  getMetadata,
  readPapiConfig,
  generate,
  add,
  ink,
  remove,
  update,
  getCli
};
//# sourceMappingURL=chunk-EIGR4EQ4.js.map